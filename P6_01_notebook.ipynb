{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P6_01_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AurelienCD/Formation_OCR_Ing_Machine_Learning/blob/main/P6_01_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connexion au google drive, déplacement dans le dossier contenant les données nécessaires au projet"
      ],
      "metadata": {
        "id": "IlnHxXmBlsGP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGCb3HvDldMe"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/Formation_OCR_Ing_Machine_Learning/Projet 6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZcPIDl0llcG",
        "outputId": "91293ef6-8b49-47c7-d59c-a5ce8770ce19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'drive/MyDrive/Formation_OCR_Ing_Machine_Learning/Projet 6'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importation des librairies nécessaires au projet"
      ],
      "metadata": {
        "id": "xAL-XrTglpoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pad \n",
        "import numpy as np\n",
        "from numpy.core.numeric import NaN\n",
        "\n",
        "import datetime\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import statistics\n",
        "from scipy import stats\n",
        "from scipy.stats import pearsonr\n",
        "from scipy.stats import ttest_ind\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "import statsmodels.stats.multicomp as multi \n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import numpy as np\n",
        "import seaborn as sn\n",
        "import pandas \n",
        "import sys, time, os\n",
        "import random\n",
        "from PIL import Image importation image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8LPf1aGln3e",
        "outputId": "22ecb8df-3e0a-4008-9287-f9f5b21a3875"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from re import X\n",
        "#importation data:\n",
        "#(X_train, y_train) , (X_test, y_test) = keras.datasets.mnist.load_data()\n",
        "#lecture du fichier excel de donnée:\n",
        "\n",
        "image_directory=\"/Images\"\n",
        "############# lecture des fichiers image ###########\n",
        "X=[]\n",
        "Y=[]\n",
        "for path, dirs, files in os.walk(image_directory):\n",
        "    for file in files:\n",
        "      print (file)\n",
        "         \n",
        "         X.append()\n",
        "         Y.append()\n",
        "         \n",
        "         \n",
        "         \n",
        "         \n",
        "          Nimageouverte=Nimageouverte+1\n",
        "            try:\n",
        "              timeRMR1 = time.time()\n",
        "              image_filepath = os.path.join(image_directory, file)\n",
        "\n",
        "\n",
        "\n",
        "def main(directory,Nom_fichier):\n",
        "    timeInit = time.time()\n",
        "    Nimageouverte=0\n",
        "    Nimagetraitees=0\n",
        "    images=[]\n",
        "    [liste_fichier,Note]=read_with_PANDAS(Nom_fichier)\n",
        "    ############# lecture des fichiers image ###########\n",
        "    for fichier in liste_fichier:\n",
        "        Nimageouverte=Nimageouverte+1\n",
        "        try:\n",
        "            timeRMR1 = time.time()\n",
        "            fichier=fichier+\".nrrd\"\n",
        "            image_filepath = os.path.join(directory, fichier)\n",
        "            images.append(sitk.GetArrayFromImage(sitk.ReadImage(image_filepath))) #ouvre l'image et la convertie en matrice numpy\n",
        "        except RuntimeError:\n",
        "            print (\"--> Probleme avec l'importation et/ou le triatement d'image\")\n",
        "    print(\"\\n\")\n",
        "    print(\"Nombre d'image total lue:\"+str(Nimageouverte)+\"\\n\")\n",
        "    timefinal = time.time()\n",
        "    TimeTotal = timefinal - timeInit\n",
        "    print(u\"Le traitement de l'ensemble des données c'est executée en \" + str(TimeTotal) +\" secondes\")\n",
        "    return images,Note\n",
        "\n",
        "##########\n",
        "directory=\"/content/images\"\n",
        "Nom_fichier=\"/content/QI_notation.csv\"\n",
        "[images,Note]=main(directory,Nom_fichier)\n",
        "\n",
        "#convert images list to array\n",
        "images=np.asarray(images)\n",
        "#Note de 5->1 à 4->0\n",
        "Note=Note-1\n",
        "plt.matshow(images[5])"
      ],
      "metadata": {
        "id": "MiyPS1t0n8DR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "olIi0jg_pAYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_directory=\"/Images\"\n",
        "############# lecture des fichiers image ###########\n",
        "for path, dirs, files in os.walk(image_directory):\n",
        "    for file in files:\n",
        "      print(file)"
      ],
      "metadata": {
        "id": "03OZyFQppAe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#normalisation:\n",
        "print(str(np.min(images)))\n",
        "print(str(np.max(images)))\n",
        "plt.matshow(images[5])\n",
        "images = images / np.max(images) #255\n",
        "print(str(np.min(images)))\n",
        "print(str(np.max(images)))\n",
        "plt.matshow(images[5])"
      ],
      "metadata": {
        "id": "kznDlopxmKtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#division des data 80, 20%\n",
        "Nvaleurs=len(images)\n",
        "N_seuil=int(Nvaleurs*0.8)\n",
        "\n",
        "list_training=random.sample(range(Nvaleurs), N_seuil)\n",
        "\n",
        "X_train=[images[i] for i in list_training]\n",
        "Y_train=[Note[i] for i in list_training]\n",
        "X_test=[images[i] for i in range(0, Nvaleurs) if i not in list_training]\n",
        "Y_test=[Note[i] for i in range(0, Nvaleurs) if i not in list_training]\n",
        "\n",
        "#convertion de model\n",
        "X_train=np.asarray(X_train)\n",
        "Y_train=np.asarray(Y_train)\n",
        "X_test=np.asarray(X_test)\n",
        "Y_test=np.asarray(Y_test)\n",
        "\n",
        "\n",
        "#(X_train, y_train) , (X_test, y_test)\n",
        "print(len(images))\n",
        "print(len(X_train))\n",
        "print(len(X_test))\n",
        "print(X_train[0].shape)\n",
        "\n",
        "plt.matshow(X_train[34])\n",
        "print(Y_train[34])"
      ],
      "metadata": {
        "id": "WFCoO3OymxVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convolutionnal neural network:\n",
        "\n",
        "IMG_SIZE = 180\n",
        "\n",
        "resize_and_rescale = tf.keras.Sequential([\n",
        "  layers.Resizing(IMG_SIZE, IMG_SIZE),\n",
        "  layers.Rescaling(1./255)\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  layers.RandomRotation(0.2),\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "cnn = models.Sequential([\n",
        "    #resize_and_rescale\n",
        "    #data_augmentation,\n",
        "\n",
        "    layers.Conv2D(filters=32, kernel_size=(4, 4), activation='relu', input_shape=(288,432,1)),\n",
        "    layers.MaxPooling2D((4, 4)),\n",
        "    \n",
        "    layers.Conv2D(filters=64, kernel_size=(2, 2), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((3, 3)),\n",
        " \n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(120, activation='softmax') #nombre de label\n",
        "])\n",
        "\n",
        "cnn.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#cnn.fit(X_train, Y_train, epochs=30)\n",
        "\n",
        "history = cnn.fit(X_train, Y_train, epochs=30, \n",
        "                    validation_data=(X_test, Y_test))\n",
        "\n",
        "\n",
        "\n",
        "cnn.summary()"
      ],
      "metadata": {
        "id": "txenq2Mgl8NN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}